{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = open('dinos.txt', 'r').read()\n",
    "data= data.lower()\n",
    "# The unique characters in the file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters ' % (data_size, vocab_size))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.170657Z",
     "iopub.execute_input": "2022-01-03T19:24:02.170940Z",
     "iopub.status.idle": "2022-01-03T19:24:02.187049Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.170906Z",
     "shell.execute_reply": "2022-01-03T19:24:02.185823Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "There are 19909 total characters and 27 unique characters in your data.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.188395Z",
     "iopub.execute_input": "2022-01-03T19:24:02.188624Z",
     "iopub.status.idle": "2022-01-03T19:24:02.201351Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.188596Z",
     "shell.execute_reply": "2022-01-03T19:24:02.200520Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](http://datascience-enthusiast.com/figures/dinos3.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def build_data(vocab_size, Tx = 40):\n",
    "    \"\"\"\n",
    "    Create a training set by scanning a window of size Tx over the text corpus, with stride 3.\n",
    "    \n",
    "    Arguments:\n",
    "    text -- string, corpus of Shakespearian poem\n",
    "    Tx -- sequence length, number of time-steps (or characters) in one training example\n",
    "    stride -- how much the window shifts itself while scanning\n",
    "    \n",
    "    Returns:\n",
    "    X -- list of training examples\n",
    "    Y -- list of training labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Build list of all dinosaur names (training examples)\n",
    "    with open(\"dinos.txt\") as f:\n",
    "        examples = f.readlines()\n",
    "    examples = [x.lower().strip() for x in examples]\n",
    "    \n",
    "    m = len(examples)\n",
    "    X = np.zeros((m, Tx, vocab_size))\n",
    "    Y = np.zeros((m, Tx, vocab_size))\n",
    "    \n",
    "    for i, name in enumerate(examples):\n",
    "        name_ids = [char_to_ix[ch] for ch in name]\n",
    "        name_onehot = tf.one_hot(name_ids, depth=27)\n",
    "        \n",
    "        X[i,0:len(name),:] = name_onehot\n",
    "        X[i,len(name):,0] = 1\n",
    "        \n",
    "        Y[i,0:len(name)-1,:] = name_onehot[1:,:]\n",
    "        Y[i,len(name)-1:,0] = 1\n",
    "    \n",
    "    print('number of training examples:', m)\n",
    "    \n",
    "    return X, Y"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.203236Z",
     "iopub.execute_input": "2022-01-03T19:24:02.203624Z",
     "iopub.status.idle": "2022-01-03T19:24:02.215396Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.203594Z",
     "shell.execute_reply": "2022-01-03T19:24:02.214617Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "X, Y = build_data(vocab_size, Tx = 40)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.216300Z",
     "iopub.execute_input": "2022-01-03T19:24:02.216522Z",
     "iopub.status.idle": "2022-01-03T19:24:02.874387Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.216498Z",
     "shell.execute_reply": "2022-01-03T19:24:02.873348Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": "\nUser settings:\n\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n   KMP_BLOCKTIME=0\n   KMP_SETTINGS=1\n   KMP_WARNINGS=0\n\nEffective settings:\n\n   KMP_ABORT_DELAY=0\n   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n   KMP_ALIGN_ALLOC=64\n   KMP_ALL_THREADPRIVATE=128\n   KMP_ATOMIC_MODE=2\n   KMP_BLOCKTIME=0\n   KMP_CPUINFO_FILE: value is not defined\n   KMP_DETERMINISTIC_REDUCTION=false\n   KMP_DEVICE_THREAD_LIMIT=2147483647\n   KMP_DISP_NUM_BUFFERS=7\n   KMP_DUPLICATE_LIB_OK=false\n   KMP_ENABLE_TASK_THROTTLING=true\n   KMP_FORCE_REDUCTION: value is not defined\n   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n   KMP_FORKJOIN_BARRIER='2,2'\n   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_GTID_MODE=3\n   KMP_HANDLE_SIGNALS=false\n   KMP_HOT_TEAMS_MAX_LEVEL=1\n   KMP_HOT_TEAMS_MODE=0\n   KMP_INIT_AT_FORK=true\n   KMP_LIBRARY=throughput\n   KMP_LOCK_KIND=queuing\n   KMP_MALLOC_POOL_INCR=1M\n   KMP_NUM_LOCKS_IN_BLOCK=1\n   KMP_PLAIN_BARRIER='2,2'\n   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_REDUCTION_BARRIER='1,1'\n   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n   KMP_SCHEDULE='static,balanced;guided,iterative'\n   KMP_SETTINGS=true\n   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n   KMP_STACKOFFSET=64\n   KMP_STACKPAD=0\n   KMP_STACKSIZE=8M\n   KMP_STORAGE_MAP=false\n   KMP_TASKING=2\n   KMP_TASKLOOP_MIN_TASKS=0\n   KMP_TASK_STEALING_CONSTRAINT=1\n   KMP_TEAMS_THREAD_LIMIT=4\n   KMP_TOPOLOGY_METHOD=all\n   KMP_USE_YIELD=1\n   KMP_VERSION=false\n   KMP_WARNINGS=false\n   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n   OMP_ALLOCATOR=omp_default_mem_alloc\n   OMP_CANCELLATION=false\n   OMP_DEFAULT_DEVICE=0\n   OMP_DISPLAY_AFFINITY=false\n   OMP_DISPLAY_ENV=false\n   OMP_DYNAMIC=false\n   OMP_MAX_ACTIVE_LEVELS=1\n   OMP_MAX_TASK_PRIORITY=0\n   OMP_NESTED: deprecated; max-active-levels-var=1\n   OMP_NUM_THREADS: value is not defined\n   OMP_PLACES: value is not defined\n   OMP_PROC_BIND='intel'\n   OMP_SCHEDULE='static'\n   OMP_STACKSIZE=8M\n   OMP_TARGET_OFFLOAD=DEFAULT\n   OMP_THREAD_LIMIT=2147483647\n   OMP_WAIT_POLICY=PASSIVE\n   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n\n2022-01-03 19:24:02.249745: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "number of training examples: 1536\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "Y.shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.875732Z",
     "iopub.execute_input": "2022-01-03T19:24:02.875988Z",
     "iopub.status.idle": "2022-01-03T19:24:02.887678Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.875952Z",
     "shell.execute_reply": "2022-01-03T19:24:02.886811Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1536, 40, 27)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from keras.models import Sequential\nfrom keras.layers import Input, Dense, GRU  # Embedding",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:02.889293Z",
     "iopub.execute_input": "2022-01-03T19:24:02.889534Z",
     "iopub.status.idle": "2022-01-03T19:24:03.749086Z",
     "shell.execute_reply.started": "2022-01-03T19:24:02.889505Z",
     "shell.execute_reply": "2022-01-03T19:24:03.748205Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class MyModel(tf.keras.Model):\n  def __init__(self, vocab_size, rnn_units):\n    super().__init__(self)\n    # self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    self.gru = tf.keras.layers.GRU(rnn_units,\n                                   return_sequences=True,\n                                   return_state=True)\n    self.dense = tf.keras.layers.Dense(vocab_size) #, activation='softmax')\n\n  def call(self, inputs, states=None, return_state=False, training=False):\n    x = inputs\n    # x = self.embedding(x, training=training)\n    if states is None:\n      states = self.gru.get_initial_state(x)\n    x, states = self.gru(x, initial_state=states, training=training)\n    x = self.dense(x, training=training)\n\n    if return_state:\n      return x, states\n    else:\n      return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:03.750078Z",
     "iopub.execute_input": "2022-01-03T19:24:03.750730Z",
     "iopub.status.idle": "2022-01-03T19:24:04.120738Z",
     "shell.execute_reply.started": "2022-01-03T19:24:03.750700Z",
     "shell.execute_reply": "2022-01-03T19:24:04.119902Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Length of the vocabulary in chars\nvocab_size = vocab_size\n\n# Number of RNN units\nrnn_units = 256\n\nmodel = MyModel(\n    vocab_size=vocab_size,\n    rnn_units=rnn_units)\nmodel.build((None, X.shape[1], X.shape[2]))\nmodel.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:04.122093Z",
     "iopub.execute_input": "2022-01-03T19:24:04.122292Z",
     "iopub.status.idle": "2022-01-03T19:24:04.477101Z",
     "shell.execute_reply.started": "2022-01-03T19:24:04.122266Z",
     "shell.execute_reply": "2022-01-03T19:24:04.475952Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"my_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru (GRU)                    multiple                  218880    \n_________________________________________________________________\ndense (Dense)                multiple                  6939      \n=================================================================\nTotal params: 225,819\nTrainable params: 225,819\nNon-trainable params: 0\n_________________________________________________________________\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "loss = tf.losses.CategoricalCrossentropy(from_logits=True)\nmodel.compile(loss=loss, optimizer='adam')  #, metrics=['accuracy'])\nhistory = model.fit(X, Y, batch_size=64, epochs=300, verbose = 2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:24:04.479583Z",
     "iopub.execute_input": "2022-01-03T19:24:04.479811Z",
     "iopub.status.idle": "2022-01-03T19:33:41.844195Z",
     "shell.execute_reply.started": "2022-01-03T19:24:04.479783Z",
     "shell.execute_reply": "2022-01-03T19:33:41.843681Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/300\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "2022-01-03 19:24:04.555378: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "24/24 - 4s - loss: 1.7370\nEpoch 2/300\n24/24 - 2s - loss: 0.9344\nEpoch 3/300\n24/24 - 2s - loss: 0.8558\nEpoch 4/300\n24/24 - 2s - loss: 0.8144\nEpoch 5/300\n24/24 - 2s - loss: 0.7734\nEpoch 6/300\n24/24 - 2s - loss: 0.7251\nEpoch 7/300\n24/24 - 2s - loss: 0.6700\nEpoch 8/300\n24/24 - 2s - loss: 0.6268\nEpoch 9/300\n24/24 - 2s - loss: 0.6029\nEpoch 10/300\n24/24 - 2s - loss: 0.5860\nEpoch 11/300\n24/24 - 2s - loss: 0.5721\nEpoch 12/300\n24/24 - 2s - loss: 0.5614\nEpoch 13/300\n24/24 - 2s - loss: 0.5517\nEpoch 14/300\n24/24 - 2s - loss: 0.5422\nEpoch 15/300\n24/24 - 2s - loss: 0.5349\nEpoch 16/300\n24/24 - 2s - loss: 0.5280\nEpoch 17/300\n24/24 - 2s - loss: 0.5222\nEpoch 18/300\n24/24 - 2s - loss: 0.5161\nEpoch 19/300\n24/24 - 2s - loss: 0.5116\nEpoch 20/300\n24/24 - 2s - loss: 0.5058\nEpoch 21/300\n24/24 - 2s - loss: 0.5010\nEpoch 22/300\n24/24 - 2s - loss: 0.4969\nEpoch 23/300\n24/24 - 2s - loss: 0.4929\nEpoch 24/300\n24/24 - 2s - loss: 0.4887\nEpoch 25/300\n24/24 - 2s - loss: 0.4847\nEpoch 26/300\n24/24 - 2s - loss: 0.4808\nEpoch 27/300\n24/24 - 2s - loss: 0.4785\nEpoch 28/300\n24/24 - 2s - loss: 0.4735\nEpoch 29/300\n24/24 - 2s - loss: 0.4700\nEpoch 30/300\n24/24 - 2s - loss: 0.4674\nEpoch 31/300\n24/24 - 2s - loss: 0.4641\nEpoch 32/300\n24/24 - 2s - loss: 0.4608\nEpoch 33/300\n24/24 - 2s - loss: 0.4577\nEpoch 34/300\n24/24 - 2s - loss: 0.4558\nEpoch 35/300\n24/24 - 2s - loss: 0.4522\nEpoch 36/300\n24/24 - 2s - loss: 0.4492\nEpoch 37/300\n24/24 - 2s - loss: 0.4471\nEpoch 38/300\n24/24 - 2s - loss: 0.4439\nEpoch 39/300\n24/24 - 2s - loss: 0.4411\nEpoch 40/300\n24/24 - 2s - loss: 0.4379\nEpoch 41/300\n24/24 - 2s - loss: 0.4353\nEpoch 42/300\n24/24 - 2s - loss: 0.4330\nEpoch 43/300\n24/24 - 2s - loss: 0.4295\nEpoch 44/300\n24/24 - 2s - loss: 0.4269\nEpoch 45/300\n24/24 - 2s - loss: 0.4243\nEpoch 46/300\n24/24 - 2s - loss: 0.4208\nEpoch 47/300\n24/24 - 2s - loss: 0.4188\nEpoch 48/300\n24/24 - 2s - loss: 0.4162\nEpoch 49/300\n24/24 - 2s - loss: 0.4133\nEpoch 50/300\n24/24 - 2s - loss: 0.4103\nEpoch 51/300\n24/24 - 2s - loss: 0.4074\nEpoch 52/300\n24/24 - 2s - loss: 0.4042\nEpoch 53/300\n24/24 - 2s - loss: 0.4010\nEpoch 54/300\n24/24 - 2s - loss: 0.3984\nEpoch 55/300\n24/24 - 2s - loss: 0.3947\nEpoch 56/300\n24/24 - 2s - loss: 0.3917\nEpoch 57/300\n24/24 - 2s - loss: 0.3883\nEpoch 58/300\n24/24 - 2s - loss: 0.3848\nEpoch 59/300\n24/24 - 2s - loss: 0.3816\nEpoch 60/300\n24/24 - 2s - loss: 0.3783\nEpoch 61/300\n24/24 - 2s - loss: 0.3739\nEpoch 62/300\n24/24 - 2s - loss: 0.3702\nEpoch 63/300\n24/24 - 2s - loss: 0.3672\nEpoch 64/300\n24/24 - 2s - loss: 0.3625\nEpoch 65/300\n24/24 - 2s - loss: 0.3590\nEpoch 66/300\n24/24 - 2s - loss: 0.3553\nEpoch 67/300\n24/24 - 2s - loss: 0.3515\nEpoch 68/300\n24/24 - 2s - loss: 0.3478\nEpoch 69/300\n24/24 - 2s - loss: 0.3430\nEpoch 70/300\n24/24 - 2s - loss: 0.3389\nEpoch 71/300\n24/24 - 2s - loss: 0.3339\nEpoch 72/300\n24/24 - 2s - loss: 0.3300\nEpoch 73/300\n24/24 - 2s - loss: 0.3254\nEpoch 74/300\n24/24 - 2s - loss: 0.3216\nEpoch 75/300\n24/24 - 2s - loss: 0.3168\nEpoch 76/300\n24/24 - 2s - loss: 0.3122\nEpoch 77/300\n24/24 - 2s - loss: 0.3073\nEpoch 78/300\n24/24 - 2s - loss: 0.3028\nEpoch 79/300\n24/24 - 2s - loss: 0.2983\nEpoch 80/300\n24/24 - 2s - loss: 0.2941\nEpoch 81/300\n24/24 - 2s - loss: 0.2897\nEpoch 82/300\n24/24 - 2s - loss: 0.2857\nEpoch 83/300\n24/24 - 2s - loss: 0.2810\nEpoch 84/300\n24/24 - 2s - loss: 0.2767\nEpoch 85/300\n24/24 - 2s - loss: 0.2734\nEpoch 86/300\n24/24 - 2s - loss: 0.2693\nEpoch 87/300\n24/24 - 2s - loss: 0.2648\nEpoch 88/300\n24/24 - 2s - loss: 0.2602\nEpoch 89/300\n24/24 - 2s - loss: 0.2563\nEpoch 90/300\n24/24 - 2s - loss: 0.2525\nEpoch 91/300\n24/24 - 2s - loss: 0.2490\nEpoch 92/300\n24/24 - 2s - loss: 0.2452\nEpoch 93/300\n24/24 - 2s - loss: 0.2421\nEpoch 94/300\n24/24 - 2s - loss: 0.2387\nEpoch 95/300\n24/24 - 2s - loss: 0.2351\nEpoch 96/300\n24/24 - 2s - loss: 0.2324\nEpoch 97/300\n24/24 - 2s - loss: 0.2292\nEpoch 98/300\n24/24 - 2s - loss: 0.2261\nEpoch 99/300\n24/24 - 2s - loss: 0.2233\nEpoch 100/300\n24/24 - 2s - loss: 0.2207\nEpoch 101/300\n24/24 - 2s - loss: 0.2176\nEpoch 102/300\n24/24 - 2s - loss: 0.2153\nEpoch 103/300\n24/24 - 2s - loss: 0.2130\nEpoch 104/300\n24/24 - 2s - loss: 0.2105\nEpoch 105/300\n24/24 - 2s - loss: 0.2082\nEpoch 106/300\n24/24 - 2s - loss: 0.2057\nEpoch 107/300\n24/24 - 2s - loss: 0.2035\nEpoch 108/300\n24/24 - 2s - loss: 0.2014\nEpoch 109/300\n24/24 - 2s - loss: 0.1993\nEpoch 110/300\n24/24 - 2s - loss: 0.1977\nEpoch 111/300\n24/24 - 2s - loss: 0.1959\nEpoch 112/300\n24/24 - 2s - loss: 0.1938\nEpoch 113/300\n24/24 - 2s - loss: 0.1918\nEpoch 114/300\n24/24 - 2s - loss: 0.1911\nEpoch 115/300\n24/24 - 2s - loss: 0.1888\nEpoch 116/300\n24/24 - 2s - loss: 0.1871\nEpoch 117/300\n24/24 - 2s - loss: 0.1856\nEpoch 118/300\n24/24 - 2s - loss: 0.1846\nEpoch 119/300\n24/24 - 2s - loss: 0.1829\nEpoch 120/300\n24/24 - 2s - loss: 0.1812\nEpoch 121/300\n24/24 - 2s - loss: 0.1802\nEpoch 122/300\n24/24 - 2s - loss: 0.1786\nEpoch 123/300\n24/24 - 2s - loss: 0.1773\nEpoch 124/300\n24/24 - 2s - loss: 0.1761\nEpoch 125/300\n24/24 - 2s - loss: 0.1756\nEpoch 126/300\n24/24 - 2s - loss: 0.1739\nEpoch 127/300\n24/24 - 2s - loss: 0.1729\nEpoch 128/300\n24/24 - 2s - loss: 0.1717\nEpoch 129/300\n24/24 - 2s - loss: 0.1706\nEpoch 130/300\n24/24 - 2s - loss: 0.1700\nEpoch 131/300\n24/24 - 2s - loss: 0.1687\nEpoch 132/300\n24/24 - 2s - loss: 0.1676\nEpoch 133/300\n24/24 - 2s - loss: 0.1665\nEpoch 134/300\n24/24 - 2s - loss: 0.1656\nEpoch 135/300\n24/24 - 2s - loss: 0.1647\nEpoch 136/300\n24/24 - 2s - loss: 0.1640\nEpoch 137/300\n24/24 - 2s - loss: 0.1632\nEpoch 138/300\n24/24 - 2s - loss: 0.1619\nEpoch 139/300\n24/24 - 2s - loss: 0.1613\nEpoch 140/300\n24/24 - 2s - loss: 0.1606\nEpoch 141/300\n24/24 - 2s - loss: 0.1600\nEpoch 142/300\n24/24 - 2s - loss: 0.1588\nEpoch 143/300\n24/24 - 2s - loss: 0.1582\nEpoch 144/300\n24/24 - 2s - loss: 0.1574\nEpoch 145/300\n24/24 - 2s - loss: 0.1571\nEpoch 146/300\n24/24 - 2s - loss: 0.1557\nEpoch 147/300\n24/24 - 2s - loss: 0.1555\nEpoch 148/300\n24/24 - 2s - loss: 0.1547\nEpoch 149/300\n24/24 - 2s - loss: 0.1540\nEpoch 150/300\n24/24 - 2s - loss: 0.1533\nEpoch 151/300\n24/24 - 2s - loss: 0.1529\nEpoch 152/300\n24/24 - 2s - loss: 0.1520\nEpoch 153/300\n24/24 - 2s - loss: 0.1514\nEpoch 154/300\n24/24 - 2s - loss: 0.1514\nEpoch 155/300\n24/24 - 2s - loss: 0.1507\nEpoch 156/300\n24/24 - 2s - loss: 0.1503\nEpoch 157/300\n24/24 - 2s - loss: 0.1494\nEpoch 158/300\n24/24 - 2s - loss: 0.1490\nEpoch 159/300\n24/24 - 2s - loss: 0.1484\nEpoch 160/300\n24/24 - 2s - loss: 0.1479\nEpoch 161/300\n24/24 - 2s - loss: 0.1474\nEpoch 162/300\n24/24 - 2s - loss: 0.1468\nEpoch 163/300\n24/24 - 2s - loss: 0.1466\nEpoch 164/300\n24/24 - 2s - loss: 0.1461\nEpoch 165/300\n24/24 - 2s - loss: 0.1450\nEpoch 166/300\n24/24 - 2s - loss: 0.1445\nEpoch 167/300\n24/24 - 2s - loss: 0.1446\nEpoch 168/300\n24/24 - 2s - loss: 0.1436\nEpoch 169/300\n24/24 - 2s - loss: 0.1436\nEpoch 170/300\n24/24 - 2s - loss: 0.1430\nEpoch 171/300\n24/24 - 2s - loss: 0.1432\nEpoch 172/300\n24/24 - 2s - loss: 0.1422\nEpoch 173/300\n24/24 - 2s - loss: 0.1419\nEpoch 174/300\n24/24 - 2s - loss: 0.1416\nEpoch 175/300\n24/24 - 2s - loss: 0.1412\nEpoch 176/300\n24/24 - 2s - loss: 0.1410\nEpoch 177/300\n24/24 - 2s - loss: 0.1402\nEpoch 178/300\n24/24 - 2s - loss: 0.1403\nEpoch 179/300\n24/24 - 2s - loss: 0.1398\nEpoch 180/300\n24/24 - 2s - loss: 0.1392\nEpoch 181/300\n24/24 - 2s - loss: 0.1391\nEpoch 182/300\n24/24 - 2s - loss: 0.1391\nEpoch 183/300\n24/24 - 2s - loss: 0.1381\nEpoch 184/300\n24/24 - 2s - loss: 0.1385\nEpoch 185/300\n24/24 - 2s - loss: 0.1376\nEpoch 186/300\n24/24 - 2s - loss: 0.1378\nEpoch 187/300\n24/24 - 2s - loss: 0.1371\nEpoch 188/300\n24/24 - 2s - loss: 0.1373\nEpoch 189/300\n24/24 - 2s - loss: 0.1360\nEpoch 190/300\n24/24 - 2s - loss: 0.1363\nEpoch 191/300\n24/24 - 2s - loss: 0.1358\nEpoch 192/300\n24/24 - 2s - loss: 0.1359\nEpoch 193/300\n24/24 - 2s - loss: 0.1350\nEpoch 194/300\n24/24 - 2s - loss: 0.1349\nEpoch 195/300\n24/24 - 2s - loss: 0.1348\nEpoch 196/300\n24/24 - 2s - loss: 0.1345\nEpoch 197/300\n24/24 - 2s - loss: 0.1346\nEpoch 198/300\n24/24 - 2s - loss: 0.1337\nEpoch 199/300\n24/24 - 2s - loss: 0.1338\nEpoch 200/300\n24/24 - 2s - loss: 0.1335\nEpoch 201/300\n24/24 - 2s - loss: 0.1333\nEpoch 202/300\n24/24 - 2s - loss: 0.1328\nEpoch 203/300\n24/24 - 2s - loss: 0.1328\nEpoch 204/300\n24/24 - 2s - loss: 0.1328\nEpoch 205/300\n24/24 - 2s - loss: 0.1322\nEpoch 206/300\n24/24 - 2s - loss: 0.1324\nEpoch 207/300\n24/24 - 2s - loss: 0.1316\nEpoch 208/300\n24/24 - 2s - loss: 0.1316\nEpoch 209/300\n24/24 - 2s - loss: 0.1313\nEpoch 210/300\n24/24 - 2s - loss: 0.1314\nEpoch 211/300\n24/24 - 2s - loss: 0.1310\nEpoch 212/300\n24/24 - 2s - loss: 0.1305\nEpoch 213/300\n24/24 - 2s - loss: 0.1307\nEpoch 214/300\n24/24 - 2s - loss: 0.1302\nEpoch 215/300\n24/24 - 2s - loss: 0.1296\nEpoch 216/300\n24/24 - 2s - loss: 0.1297\nEpoch 217/300\n24/24 - 2s - loss: 0.1299\nEpoch 218/300\n24/24 - 2s - loss: 0.1301\nEpoch 219/300\n24/24 - 2s - loss: 0.1295\nEpoch 220/300\n24/24 - 2s - loss: 0.1289\nEpoch 221/300\n24/24 - 2s - loss: 0.1290\nEpoch 222/300\n24/24 - 2s - loss: 0.1290\nEpoch 223/300\n24/24 - 2s - loss: 0.1294\nEpoch 224/300\n24/24 - 2s - loss: 0.1286\nEpoch 225/300\n24/24 - 2s - loss: 0.1283\nEpoch 226/300\n24/24 - 2s - loss: 0.1279\nEpoch 227/300\n24/24 - 2s - loss: 0.1279\nEpoch 228/300\n24/24 - 2s - loss: 0.1278\nEpoch 229/300\n24/24 - 2s - loss: 0.1280\nEpoch 230/300\n24/24 - 2s - loss: 0.1275\nEpoch 231/300\n24/24 - 2s - loss: 0.1270\nEpoch 232/300\n24/24 - 2s - loss: 0.1271\nEpoch 233/300\n24/24 - 2s - loss: 0.1268\nEpoch 234/300\n24/24 - 2s - loss: 0.1266\nEpoch 235/300\n24/24 - 2s - loss: 0.1268\nEpoch 236/300\n24/24 - 2s - loss: 0.1267\nEpoch 237/300\n24/24 - 2s - loss: 0.1263\nEpoch 238/300\n24/24 - 2s - loss: 0.1266\nEpoch 239/300\n24/24 - 2s - loss: 0.1262\nEpoch 240/300\n24/24 - 2s - loss: 0.1259\nEpoch 241/300\n24/24 - 2s - loss: 0.1261\nEpoch 242/300\n24/24 - 2s - loss: 0.1258\nEpoch 243/300\n24/24 - 2s - loss: 0.1259\nEpoch 244/300\n24/24 - 2s - loss: 0.1256\nEpoch 245/300\n24/24 - 2s - loss: 0.1257\nEpoch 246/300\n24/24 - 2s - loss: 0.1253\nEpoch 247/300\n24/24 - 2s - loss: 0.1253\nEpoch 248/300\n24/24 - 2s - loss: 0.1250\nEpoch 249/300\n24/24 - 2s - loss: 0.1250\nEpoch 250/300\n24/24 - 2s - loss: 0.1249\nEpoch 251/300\n24/24 - 2s - loss: 0.1244\nEpoch 252/300\n24/24 - 2s - loss: 0.1248\nEpoch 253/300\n24/24 - 2s - loss: 0.1247\nEpoch 254/300\n24/24 - 2s - loss: 0.1246\nEpoch 255/300\n24/24 - 2s - loss: 0.1244\nEpoch 256/300\n24/24 - 2s - loss: 0.1239\nEpoch 257/300\n24/24 - 2s - loss: 0.1242\nEpoch 258/300\n24/24 - 2s - loss: 0.1239\nEpoch 259/300\n24/24 - 2s - loss: 0.1236\nEpoch 260/300\n24/24 - 2s - loss: 0.1238\nEpoch 261/300\n24/24 - 2s - loss: 0.1238\nEpoch 262/300\n24/24 - 2s - loss: 0.1236\nEpoch 263/300\n24/24 - 2s - loss: 0.1233\nEpoch 264/300\n24/24 - 2s - loss: 0.1233\nEpoch 265/300\n24/24 - 2s - loss: 0.1232\nEpoch 266/300\n24/24 - 2s - loss: 0.1234\nEpoch 267/300\n24/24 - 2s - loss: 0.1231\nEpoch 268/300\n24/24 - 2s - loss: 0.1228\nEpoch 269/300\n24/24 - 2s - loss: 0.1228\nEpoch 270/300\n24/24 - 2s - loss: 0.1229\nEpoch 271/300\n24/24 - 2s - loss: 0.1225\nEpoch 272/300\n24/24 - 2s - loss: 0.1225\nEpoch 273/300\n24/24 - 2s - loss: 0.1225\nEpoch 274/300\n24/24 - 2s - loss: 0.1222\nEpoch 275/300\n24/24 - 2s - loss: 0.1223\nEpoch 276/300\n24/24 - 2s - loss: 0.1222\nEpoch 277/300\n24/24 - 2s - loss: 0.1222\nEpoch 278/300\n24/24 - 2s - loss: 0.1220\nEpoch 279/300\n24/24 - 2s - loss: 0.1221\nEpoch 280/300\n24/24 - 2s - loss: 0.1220\nEpoch 281/300\n24/24 - 2s - loss: 0.1219\nEpoch 282/300\n24/24 - 2s - loss: 0.1220\nEpoch 283/300\n24/24 - 2s - loss: 0.1219\nEpoch 284/300\n24/24 - 2s - loss: 0.1218\nEpoch 285/300\n24/24 - 2s - loss: 0.1216\nEpoch 286/300\n24/24 - 2s - loss: 0.1217\nEpoch 287/300\n24/24 - 2s - loss: 0.1215\nEpoch 288/300\n24/24 - 2s - loss: 0.1215\nEpoch 289/300\n24/24 - 2s - loss: 0.1213\nEpoch 290/300\n24/24 - 2s - loss: 0.1213\nEpoch 291/300\n24/24 - 2s - loss: 0.1215\nEpoch 292/300\n24/24 - 2s - loss: 0.1213\nEpoch 293/300\n24/24 - 2s - loss: 0.1211\nEpoch 294/300\n24/24 - 2s - loss: 0.1211\nEpoch 295/300\n24/24 - 2s - loss: 0.1208\nEpoch 296/300\n24/24 - 2s - loss: 0.1207\nEpoch 297/300\n24/24 - 2s - loss: 0.1207\nEpoch 298/300\n24/24 - 2s - loss: 0.1204\nEpoch 299/300\n24/24 - 2s - loss: 0.1207\nEpoch 300/300\n24/24 - 2s - loss: 0.1209\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "class OneStep(tf.keras.Model):\n  def __init__(self, model):\n    super().__init__()\n    self.model = model\n\n\n  def generate_one_step(self, inputs, states=None, Tx=1, vocab_size=27):\n    # Convert strings to token IDs.\n    input_x = np.zeros((1, len(inputs), vocab_size))\n    name_ids = [char_to_ix[ch] for ch in inputs]\n    name_onehot = tf.one_hot(name_ids, depth=27)\n    input_x[0,:,:] = name_onehot\n    \n    input_x = tf.constant(input_x)\n\n    # Run the model.\n    predicted_logits, states = self.model(inputs=input_x, states=states,\n                                          return_state=True)\n    # Only use the last prediction.\n    predicted_logits = predicted_logits[:, -1, :]\n\n    # Sample the output logits to generate token IDs.\n    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n\n    # Convert from token ids to characters\n    predicted_chars = ''.join(ix_to_char[index] for index in predicted_ids.numpy())\n\n    # Return the characters and model state.\n    return predicted_chars, states\n\none_step_model = OneStep(model)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:33:41.845030Z",
     "iopub.execute_input": "2022-01-03T19:33:41.845219Z",
     "iopub.status.idle": "2022-01-03T19:33:41.858998Z",
     "shell.execute_reply.started": "2022-01-03T19:33:41.845194Z",
     "shell.execute_reply": "2022-01-03T19:33:41.858536Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "start = time.time()\n\n# Generate 10 dinasaurus names beginning with 'm'\nfor i in range(10):\n    states = None\n    next_char = 'm'\n    result = [next_char]\n    for n in range(20):\n        next_char, states = one_step_model.generate_one_step(next_char, states=states)\n        if next_char=='\\n':\n            break\n        result.append(next_char)\n    result = tf.strings.join(result)\n    result = result.numpy().decode('utf-8')\n    result = result[0].upper() + result[1:]\n    print(result)\n\nend = time.time()\nprint('\\nRun time:', end - start)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T19:33:41.859836Z",
     "iopub.execute_input": "2022-01-03T19:33:41.860360Z",
     "iopub.status.idle": "2022-01-03T19:33:42.515471Z",
     "shell.execute_reply.started": "2022-01-03T19:33:41.860334Z",
     "shell.execute_reply": "2022-01-03T19:33:42.514611Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "Mendozasaurus\nMendozasaurus\nMamenchisaurus\nMtapaiasaurus\nMicroceratus\nMourocosaurus\nMei\nMicroraptor\nMicroraptor\nMerrudiceratops\n\nRun time: 0.6334753036499023\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}